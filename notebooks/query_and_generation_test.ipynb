{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG.qdrant_database import QdrantDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91790\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "qdrant = QdrantDatabase(\n",
    "        cluster_uri=\"https://904197e5-0ed4-48c7-9642-0611912311c7.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "        api=os.getenv(\"DB_API\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91790\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How can i train my persian cat?\"\n",
    "matches = qdrant.query_db(collection_name='furr_bot', limits=2, query=prompt)\n",
    "context = \"\"\n",
    "for match in matches: \n",
    "    context += match.get('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"persian training persian cats are intelligent and can be trained to respond to cues with the help of a clicker and positive reinforcement. like any cat, the success of training may depend on the individual cat—as well as patience and commitment from their pet parent.behavior and training tips for persian cats persian cat personality and temperament shuter and quandt describe persian cats as habitual creatures who prefer a calm and quiet lifestyle. “they’re especially susceptible to changes in the environment around them,” shuter explains. persians are better suited for households with older children than those with toddlers or babies. while persian cats can coexist peacefully with other cats and friendly dogs who don't chase or play rough, introductions to new pets should be done slowly and with care.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamlit_src.llm import gen, stream_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian cats are intelligent and can be trained with a clicker and positive reinforcement. It's important to be patient and committed during the training process. Introductions to new pets should be done slowly and with care.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    gen(\"gpt-3.5-turbo\", context, prompt)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can train your Persian cat using a clicker and positive reinforcement, being patient and committed. Persians prefer a calm environment and respond well to training with consistency. Introduce them slowly to new pets for peaceful coexistence.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    stream_gen(\"gpt-3.5-turbo\", context, prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, ChatSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=\"gen-lang-client-0718497449\", location=\"asia-south1\")\n",
    "model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat_session = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        text_response.append(chunk.text)\n",
    "    return \"\".join(text_response)\n",
    "\n",
    "prompt = \"Hello.\"\n",
    "# print(get_chat_response(chat_session, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework for developing applications powered by language models.  Instead of just using a language model as a standalone tool, LangChain provides a way to connect them to other sources of data and functionality, making them far more powerful and versatile.  Think of it as a toolbox for building more complex and useful applications on top of LLMs (Large Language Models) like GPT-3, LLaMA, etc.\n",
      "\n",
      "Here's a breakdown of its key features and capabilities:\n",
      "\n",
      "* **Modular Components:** LangChain breaks down the process of building LLM-powered applications into reusable modules.  This includes:\n",
      "    * **Models:**  The LLMs themselves (e.g., OpenAI's GPT models, Hugging Face models).\n",
      "    * **Prompts:**  The carefully crafted instructions given to the LLM to elicit the desired response. LangChain helps manage and optimize prompts.\n",
      "    * **Indexes:**  Mechanisms to connect the LLM to external data sources, allowing it to access and process information beyond its training data.  This could include documents, databases, or APIs.\n",
      "    * **Chains:**  Sequences of calls to LLMs and other components, allowing you to build complex workflows.  For example, you might chain together a retrieval step (from an index), a question answering step (from an LLM), and a summarization step.\n",
      "    * **Agents:**  Components that decide which tools (e.g., LLMs, calculators, search engines) to use and in what order to solve a given task.  This enables more autonomous and adaptable applications.\n",
      "    * **Memory:**  Allows you to maintain context across multiple interactions with the LLM, enabling more coherent and personalized conversations.\n",
      "\n",
      "* **Ease of Use:** LangChain aims to simplify the development process by providing a consistent and intuitive API.  This makes it easier to experiment with different LLMs, prompts, and data sources.\n",
      "\n",
      "* **Extensibility:**  LangChain is designed to be easily extended with custom components, allowing developers to integrate their own tools and functionalities.\n",
      "\n",
      "* **Integration with various LLMs and data sources:** It supports numerous LLMs and can connect to a wide variety of data sources.\n",
      "\n",
      "\n",
      "**In short:** LangChain helps you build applications that go beyond simple question-answering by connecting LLMs to your data and other tools, enabling more sophisticated and useful functionalities.  Think of applications like:\n",
      "\n",
      "* **Chatbots with access to your knowledge base:**  A chatbot that can answer questions based on your company's internal documents.\n",
      "* **Intelligent assistants:** An assistant that can perform complex tasks by combining multiple tools and LLMs.\n",
      "* **Customizable search engines:** A search engine that understands natural language queries and retrieves relevant information.\n",
      "* **Automated document processing:** An application that automatically extracts information from documents.\n",
      "\n",
      "\n",
      "LangChain is a powerful tool for anyone looking to build advanced applications using large language models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic gemini \n",
    "import os \n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "prompt = \"WHat is langchain\"\n",
    "# res \n",
    "response = model.generate_content(prompt)\n",
    "text = response.text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
