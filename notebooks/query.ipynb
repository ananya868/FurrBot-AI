{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG.qdrant_database import QdrantDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91790\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "api = os.environ.get('DB_API')\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qd = QdrantDatabase(\n",
    "    cluster_uri=\"Cluster uri here!\",\n",
    "    api=api\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='furr_bot')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get collection \n",
    "qd.client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "lst = ['a', 'b', 'c', 'd', 'e']\n",
    "print(lst[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Re-Ranking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "# check time for code run\n",
    "import time\n",
    "\n",
    "def chat(prompt):\n",
    "    client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "    completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a member of a chatbot system, your responsibility is to analyze the previous conversation and current user query, and determine whether the user is asking for a new information or wants to continue with previous conversation\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "    answer = completion.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "\n",
    "def do_retrieval(conversation, query):\n",
    "    prompt = f\"\"\"  \n",
    "                Determine whether user is asking for new information or wants to continue with previous conversation.\n",
    "                Conversation: {conversation}\n",
    "                Query: {query}\n",
    "                Your answer should be either \"True\" for new information or \"False\" for previous conversation.\n",
    "            \"\"\"\n",
    "    answer = chat(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = \"How should i feed my hamster?\"\n",
    "query = \"how to train my him?\"\n",
    "\n",
    "do_retrieval(con, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"so how should i treat him?\"\n",
    "res = qd.client.query_points(\n",
    "    collection_name =\"furr_bot\",\n",
    "    query = encoder.encode(query).tolist(),\n",
    "    limit=3,\n",
    "    query_filter = models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"word_count\",\n",
    "                range=models.Range(\n",
    "                    gte=40, \n",
    "                    lte=300\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = res.points[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"treatment the anchor worm can be easily removed by carefully pulling it out from the fish's skin. the infected area is then treated with a topical antibiotic ointment. afterwards, the pond or aquarium should be sanitized and disinfected, in an effort to remove any adult parasites, larvae or eggs. /24, \",\n",
       " 'topic': 'Treatment',\n",
       " 'blog_name': 'Anchor Worm Symptoms - Fish',\n",
       " 'pet': 'Fish',\n",
       " 'word_count': 50,\n",
       " 'chunk_size': 58}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = []\n",
    "for a in ans:\n",
    "    d = a.payload\n",
    "    d['score'] = a.score\n",
    "    paras.append(\n",
    "        d\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"living and management first and foremost, your hamster needs plenty of rest in a calm, clean, and sanitary environment. consult your veterinarian to formulate a diet that meets the hamster's special needs and follow any other instructions your veterinarian may have given. /24, \",\n",
       "  'topic': 'Living and Management',\n",
       "  'blog_name': 'Inflammation of the Kidneys in Hamsters',\n",
       "  'pet': 'Hamsters',\n",
       "  'word_count': 43,\n",
       "  'chunk_size': 50,\n",
       "  'score': 0.72854924},\n",
       " {'text': \"living and management while recovering from the toxicity, the hamster should be monitored for symptoms indicating an allergic relapse. in addition, consult your veterinarian about the hamster's dietary requirements during the recovery period. if your pet refuses to eat, /24, force-feeding may be necessary.\",\n",
       "  'topic': 'Living and Management',\n",
       "  'blog_name': 'Antibiotics-Induced Enteritis in Hamsters',\n",
       "  'pet': 'Hamsters',\n",
       "  'word_count': 44,\n",
       "  'chunk_size': 53,\n",
       "  'score': 0.7004651}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
